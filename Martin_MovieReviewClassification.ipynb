{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CEs4pn8AHNI",
        "outputId": "7e7e1824-4bc2-4b7b-9bc6-007e00f67d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification\n"
          ]
        }
      ],
      "source": [
        "#mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#change directory\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/Machine Learning/Datasets/SentimentClassification\")\n",
        "#print out the current directory\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmpxx5UzV29P",
        "outputId": "87b86c7d-d125-4cf5-8eac-5a461eef2873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyprind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlRjPoR7CPjj",
        "outputId": "3f853a6d-4c71-4b56-ab24-a86cf8e5961b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AFsWo_ckoDi",
        "outputId": "18300280-1396-488d-814f-917056717868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aclImdb  classifier.pkl  Martin_MovieReviewClassification.ipynb  stopwords.pkl\tvectorizer.py\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOPzMLahYz9k",
        "outputId": "eb3e446c-1b84-4328-a83b-e561465d9f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['vectorizer.py', 'classifier.pkl', 'stopwords.pkl', 'Martin_MovieReviewClassification.ipynb', 'aclImdb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1rUV51BWI5V",
        "outputId": "7b347353-6f42-4c19-b072-018453e0710d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  I went and saw this movie last night after bei...          1\n",
            "1  Actor turned director Bill Paxton follows up h...          1\n",
            "2  As a recreational golfer with some knowledge o...          1\n",
            "3  I saw this film in a sneak preview, and it is ...          1\n",
            "4  Bill Paxton has taken the true story of the 19...          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Total time elapsed: 00:36:23\n"
          ]
        }
      ],
      "source": [
        "import pyprind\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# change the 'basepath' to the directory of the unzipped movie dataset\n",
        "basepath = '/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification/aclImdb'\n",
        "\n",
        "labels = {'pos': 1, 'neg': 0}\n",
        "pbar = pyprind.ProgBar(50000)\n",
        "data_list = []  # Create an empty list to store data\n",
        "\n",
        "for s in ('test', 'train'):\n",
        "    for l in ('pos', 'neg'):\n",
        "        path = os.path.join(basepath, s, l)\n",
        "        for file in sorted(os.listdir(path)):\n",
        "            file_path = os.path.join(path, file)\n",
        "            with open(file_path, 'r', encoding='utf-8') as infile:\n",
        "                txt = infile.read()\n",
        "            # Append data as dictionary to data_list\n",
        "            data_list.append({'review': txt, 'sentiment': labels[l]})\n",
        "            pbar.update()\n",
        "\n",
        "# Concatenate data_list into a DataFrame\n",
        "df = pd.concat([pd.DataFrame(data_list)])\n",
        "\n",
        "# Rename columns\n",
        "df.columns = ['review', 'sentiment']\n",
        "\n",
        "# Print the first few rows of the DataFrame\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification/movie_data.csv', encoding='utf-8')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Now you can perform operations on df\n",
        "np.random.seed(0)\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df.to_csv('movie_data.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Reading back the shuffled data to confirm\n",
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "print(df.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwq6fwxTWClY",
        "outputId": "5f61869d-6327-4bc8-d4cf-8b1474282b28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  election is a chinese mob movie or triads in t...          1\n",
            "1  i was just watching a forensic files marathon ...          0\n",
            "2  police story is a stunning series of set piece...          1\n",
            "3  dear readers the final battle between the rebe...          1\n",
            "4  i have seen the perfect son about three times ...          1\n",
            "                                              review  sentiment\n",
            "0  at a saturday matinee in my home town i went w...          0\n",
            "1  i love this movie it is the first film master ...          1\n",
            "2  in the voice over which begins the film hughie...          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUH8L2VzZfxx",
        "outputId": "5592fa68-b30a-49aa-df3a-f1c759a43ba0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer()\n",
        "docs = np.array(['The sun is shining',\n",
        "                 'The weather is sweet',\n",
        "                 'The sun is shining, the weather is sweet,'\n",
        "                 'and one and one is two'])\n",
        "bag = count.fit_transform(docs)"
      ],
      "metadata": {
        "id": "a0aqm-CPZ456"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf = TfidfTransformer(use_idf=True,\n",
        "                         norm='l2',\n",
        "                         smooth_idf=True)\n",
        "np.set_printoptions(precision=2)\n",
        "print(tfidf.fit_transform(count.fit_transform(docs)) .toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGhZrGjymc0k",
        "outputId": "5748dda8-e5ce-466f-d098-6f4fe67f1f2f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
            " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
            " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0, 'review'][-50:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ntnk6B1UmhWh",
        "outputId": "47c58f4c-649e-4857-82c3-411ad2bcb0d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' hippies only or if you re stoned i give this a 1 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def preprocessor(text):\n",
        "    text = re.sub(r'<[^>]*>', '', text)\n",
        "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text)\n",
        "    text = (re.sub(r'[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text"
      ],
      "metadata": {
        "id": "DUwwM9pKmknU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(df.loc[0, 'review'][-50:])\n",
        "\n",
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "u97V_IcunO4_",
        "outputId": "e32ad900-7cfc-4ea1-b051-e8d3a9c8b5cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a test :) :( :)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['review'] = df['review'].apply(preprocessor)"
      ],
      "metadata": {
        "id": "wsT0ebwdnYn_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "tokenizer('runners like running and thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj4J4YrbnnMM",
        "outputId": "bce4475e-00bd-46b0-dd7b-e0621dcf1546"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "tokenizer_porter('runners like running and thus they run')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JYAliVonsUv",
        "outputId": "2b906ccb-4fde-4dd0-8c9e-ca9e61e670f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "[w for w in tokenizer_porter('a runner likes' ' running and runs a lot')[-10:] if w not in stop]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQzYPOn1pSDV",
        "outputId": "1cc2dcb9-4727-42ec-f8e7-0199e7dc3bbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['runner', 'like', 'run', 'run', 'lot']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "IRCXC_mGn2Rz",
        "outputId": "43de4671-b4ad-4723-8f97-793f7950e815"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                   review  sentiment\n",
              "0      at a saturday matinee in my home town i went w...          0\n",
              "1      i love this movie it is the first film master ...          1\n",
              "2      in the voice over which begins the film hughie...          1\n",
              "3       spoiler alert the point is though that i didn...          0\n",
              "4      this is an excellent film no it s not mel gibs...          1\n",
              "...                                                  ...        ...\n",
              "49995  although the director tried the filming was ma...          0\n",
              "49996  it has been about 50 years since a movie has b...          1\n",
              "49997   bar hopping seems to be trying to be about th...          0\n",
              "49998  this awful effort just goes to show what happe...          0\n",
              "49999  yes why among the filmmakers that came out in ...          0\n",
              "\n",
              "[50000 rows x 2 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.head</b><br/>def head(n: int=5) -&gt; NDFrameT</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Return the first `n` rows.\n",
              "\n",
              "This function returns the first `n` rows for the object based\n",
              "on position. It is useful for quickly testing if your object\n",
              "has the right type of data in it.\n",
              "\n",
              "For negative values of `n`, this function returns all rows except\n",
              "the last `|n|` rows, equivalent to ``df[:n]``.\n",
              "\n",
              "If n is larger than the number of rows, this function returns all rows.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "n : int, default 5\n",
              "    Number of rows to select.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "same type as caller\n",
              "    The first `n` rows of the caller object.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.tail: Returns the last `n` rows.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;animal&#x27;: [&#x27;alligator&#x27;, &#x27;bee&#x27;, &#x27;falcon&#x27;, &#x27;lion&#x27;,\n",
              "...                    &#x27;monkey&#x27;, &#x27;parrot&#x27;, &#x27;shark&#x27;, &#x27;whale&#x27;, &#x27;zebra&#x27;]})\n",
              "&gt;&gt;&gt; df\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot\n",
              "6      shark\n",
              "7      whale\n",
              "8      zebra\n",
              "\n",
              "Viewing the first 5 lines\n",
              "\n",
              "&gt;&gt;&gt; df.head()\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "\n",
              "Viewing the first `n` lines (three in this case)\n",
              "\n",
              "&gt;&gt;&gt; df.head(3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "\n",
              "For negative values of `n`\n",
              "\n",
              "&gt;&gt;&gt; df.head(-3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5559);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.loc[:25000, 'review'].values\n",
        "y_train = df.loc[:25000, 'sentiment'].values\n",
        "X_test = df.loc[25000:, 'review'].values\n",
        "y_test = df.loc[25000:, 'sentiment'].values"
      ],
      "metadata": {
        "id": "-JTyqecDqIlR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None)\n",
        "# param_grid = [{'vect__ngram_range': [(1,1)],\n",
        "#                 'vect__stop_words': [stop, None],\n",
        "#                 'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "#                 'clf__penalty': ['l1', 'l2'],\n",
        "#                 'clf__C': [1.0, 10.0, 100.0]},\n",
        "#                 {'vect__ngram_range': [(1,1)],\n",
        "#                 'vect__stop_words': [stop, None],\n",
        "#                 'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "#                 'vect__use_idf':[False],\n",
        "#                 'vect__norm':[None],\n",
        "#                 'clf__penalty': ['l1', 'l2'],\n",
        "#                 'clf__C': [1.0, 10.0, 100.0]}\n",
        "#             ]\n",
        "# lr_tfidf = Pipeline([('vect', tfidf), ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
        "# gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy', cv=5, verbose=2, n_jobs=-1)\n",
        "# gs_lr_tfidf.fit(X_train, y_train)\n",
        "\n",
        "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False)\n",
        "param_grid = {\n",
        "    'vect__ngram_range': [(1, 1)],\n",
        "    'clf__C': [1.0, 10.0]\n",
        "}\n",
        "\n",
        "lr_tfidf = Pipeline([\n",
        "    ('vect', tfidf),\n",
        "    ('clf', LogisticRegression(random_state=0, solver='liblinear'))\n",
        "])\n",
        "\n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, scoring='accuracy', cv=3, verbose=2)\n",
        "gs_lr_tfidf.fit(X_train, y_train) #Previous code took over an hour and did not even finish, so made smaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wzsOm3BhqPEk",
        "outputId": "e19fa1d4-a5e4-45de-d3e3-c40217746b5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV] END ...............clf__C=1.0, vect__ngram_range=(1, 1); total time=   7.4s\n",
            "[CV] END ...............clf__C=1.0, vect__ngram_range=(1, 1); total time=   7.0s\n",
            "[CV] END ...............clf__C=1.0, vect__ngram_range=(1, 1); total time=   5.8s\n",
            "[CV] END ..............clf__C=10.0, vect__ngram_range=(1, 1); total time=   8.7s\n",
            "[CV] END ..............clf__C=10.0, vect__ngram_range=(1, 1); total time=   8.2s\n",
            "[CV] END ..............clf__C=10.0, vect__ngram_range=(1, 1); total time=   7.4s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(lowercase=False)),\n",
              "                                       ('clf',\n",
              "                                        LogisticRegression(random_state=0,\n",
              "                                                           solver='liblinear'))]),\n",
              "             param_grid={'clf__C': [1.0, 10.0], 'vect__ngram_range': [(1, 1)]},\n",
              "             scoring='accuracy', verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                        TfidfVectorizer(lowercase=False)),\n",
              "                                       (&#x27;clf&#x27;,\n",
              "                                        LogisticRegression(random_state=0,\n",
              "                                                           solver=&#x27;liblinear&#x27;))]),\n",
              "             param_grid={&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;vect__ngram_range&#x27;: [(1, 1)]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                        TfidfVectorizer(lowercase=False)),\n",
              "                                       (&#x27;clf&#x27;,\n",
              "                                        LogisticRegression(random_state=0,\n",
              "                                                           solver=&#x27;liblinear&#x27;))]),\n",
              "             param_grid={&#x27;clf__C&#x27;: [1.0, 10.0], &#x27;vect__ngram_range&#x27;: [(1, 1)]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, TfidfVectorizer(lowercase=False)),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(lowercase=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkRtNq6DHqbe",
        "outputId": "16a46b3c-d626-4b49-b610-94ec9e211a08"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameter set: {'clf__C': 10.0, 'vect__ngram_range': (1, 1)} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9EIezdII5Ai",
        "outputId": "db4bcf38-fb4f-45d0-e61d-af5823181262"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy: 0.890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE8f13sRMFW6",
        "outputId": "fa0d9868-3d13-487d-b8ce-57a7058c3cc2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "def tokenizer(text):\n",
        "    text = re.sub(r'<[^>]*>', '', text)\n",
        "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub(r'[\\W]+', ' ', text.lower()) \\\n",
        "                    + ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = [w for w in text.split() if w not in stop]\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "U1N184NXTQCP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_docs(path):\n",
        "    with open(path, 'r', encoding='utf-8') as csv:\n",
        "        next(csv)  # skip header\n",
        "        for line in csv:\n",
        "            line = line.strip().split(',')\n",
        "            text, label = ','.join(line[:-1]), int(line[-1])\n",
        "            yield text, label"
      ],
      "metadata": {
        "id": "_scbOQMNTVZI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_stream = stream_docs(path='/content/drive/My Drive/Machine Learning/Datasets/SentimentClassification/movie_data.csv')\n",
        "print(next(doc_stream))  # This should print the first (text, label) tuple correctly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cai3PS5TX5t",
        "outputId": "0675f976-2d99-49d8-808f-949b6e0d73a5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('at a saturday matinee in my home town i went with an older friend he was about 12 and my mom let me go because she thought the film would be ok it s rated g i was assaulted by loud music strange images no plot and a stubborn refusal to make any sense we left halfway through because we were bored frustrated and our ears hurt i saw it 22 years later in a revival theatre my opinion had changed it s even worse basically everything i hated about it was still there and the film was very 60s and has dated badly i got all the little in jokes too bad they weren t funny the constant shifts in tone got quickly annoying and there s absolutely nothing to get a firm grip on some people will love this i found it frustrating by the end of the film i felt like throwing something heavy at the screen also all the monkees songs in this movie suck and i do like them for ex hippies only or if you re stoned i give this a 1 ', 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_minibatch(doc_stream, size):\n",
        "    docs, y = [], []\n",
        "    try:\n",
        "        for _ in range(size):\n",
        "            text, label = next(doc_stream)\n",
        "            docs.append(text)\n",
        "            y.append(label)\n",
        "    except StopIteration:\n",
        "        return None, None\n",
        "    return docs, y"
      ],
      "metadata": {
        "id": "UQvm0WKQXvXM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "vect = HashingVectorizer(decode_error='ignore', n_features=2**21, preprocessor=None, tokenizer=tokenizer)\n",
        "clf = SGDClassifier(loss='log_loss', random_state=1)\n",
        "doc_stream = stream_docs(path='movie_data.csv')"
      ],
      "metadata": {
        "id": "TkwHpnSJXyJk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyprind\n",
        "pbar = pyprind.ProgBar(45)\n",
        "classes = np.array([0, 1])\n",
        "\n",
        "\n",
        "for _ in range(45):\n",
        "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
        "    if not X_train:\n",
        "        break\n",
        "    X_train = vect.transform(X_train)\n",
        "    clf.partial_fit(X_train, y_train, classes=classes)\n",
        "    pbar.update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU-ngfO2X122",
        "outputId": "22bf848c-1ef6-44ea-c4af-2c71d6d17ad3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
        "X_test = vect.transform(X_test)\n",
        "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qct5wUOAYgo8",
        "outputId": "51002b3e-fef5-4293-890b-f36b08fc53ff"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = clf.partial_fit(X_test, y_test)"
      ],
      "metadata": {
        "id": "HMPvu2cIYx8x"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "qpxW1CYkYynJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer(stop_words='english', max_df=.1, max_features=5000)\n",
        "X = count.fit_transform(df['review'].values)"
      ],
      "metadata": {
        "id": "dYTp1UawY1FK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=123, learning_method='batch')\n",
        "X_topics = lda.fit_transform(X)"
      ],
      "metadata": {
        "id": "qDv78voBZ2fD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda.components_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwSvzWCKbzDY",
        "outputId": "e19fba4b-575b-4ac7-eee4-fcaf2e26e589"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "    print(\"Topic %d:\" % (topic_idx + 1))\n",
        "    print(\" \".join([feature_names[i]\n",
        "        for i in topic.argsort()\\\n",
        "        [:-n_top_words - 1:-1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BOLWU0XeD0q",
        "outputId": "923efe10-cbd7-4e83-92fa-4e8c965dc649"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1:\n",
            "horror original comedy black house\n",
            "Topic 2:\n",
            "worst minutes guy script money\n",
            "Topic 3:\n",
            "book dvd read version original\n",
            "Topic 4:\n",
            "family performance beautiful father mother\n",
            "Topic 5:\n",
            "series episode tv comedy kids\n",
            "Topic 6:\n",
            "murder wife police john plays\n",
            "Topic 7:\n",
            "documentary camera audience war human\n",
            "Topic 8:\n",
            "music song songs musical role\n",
            "Topic 9:\n",
            "horror effects guy budget special\n",
            "Topic 10:\n",
            "action game war fight animation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horror = X_topics[:, 5].argsort()[::-1]\n",
        "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
        "    print('\\nHorror movie #%d:' % (iter_idx + 1))\n",
        "    print(df['review'][movie_idx][:300], '...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BKLI4kHeLYE",
        "outputId": "2d06c512-4541-4e13-d546-fef6eb79553f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Horror movie #1:\n",
            " spoilers when undercover brooklyn north det eddie santos nestor serrano was to meet his drug supplier tito zapatti larry romano in the williamsburg section of brooklyn in a buy and bust operation with tito being the one who gets busted that things went haywire with both det santos and tito ending u ...\n",
            "\n",
            "Horror movie #2:\n",
            " spoilers extremely brutal police drama set in san francisco involving a sting operation that goes terribly wrong a cop det falon sam elliott mistakenly and savagely beats to death an undercover policeman winch mike watson thinking that he murdered his partner det sam levinson mike burstyn a partner ...\n",
            "\n",
            "Horror movie #3:\n",
            "this first rate western tale of the gold rush brings great excitement romance and james stewart to the screen the far country is the only one out of all five stewart mann westerns that is often overlooked stewart yet again puts a new look on the ever present personalities he had in the five stewart  ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_docs = 10\n",
        "for topic_idx in range(X_topics.shape[1]):\n",
        "    print(\"\\nTopic #{}:\".format(topic_idx + 1))\n",
        "    top_doc_indices = X_topics[:, topic_idx].argsort()[::-1][:n_docs]\n",
        "    for doc_index in top_doc_indices:\n",
        "        print(df['review'][doc_index][:300])  # Print the first 300 characters of each top document"
      ],
      "metadata": {
        "id": "1bi52ejvfCQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
        "if not os.path.exists(dest):\n",
        "    os.makedirs(dest)\n",
        "pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'), 'wb'), protocol=4)\n",
        "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)"
      ],
      "metadata": {
        "id": "j62Xwz7VgKJ1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import os\n",
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "\n",
        "c = conn.cursor()\n",
        "c.execute('DROP TABLE IF EXISTS review_db')\n",
        "c.execute('CREATE TABLE review_db' ' (review TEXT, sentiment INTEGER, date TEXT)')\n",
        "example1 = 'I love this movie'\n",
        "c.execute(\"INSERT INTO review_db\" \" (review, sentiment, date) VALUES\" \" (?, ?, DATETIME('now'))\", (example1, 1))\n",
        "example2 = 'I disliked this movie'\n",
        "c.execute(\"INSERT INTO review_db\" \" (review, sentiment, date) VALUES\" \" (?, ?, DATETIME('now'))\", (example2, 0))\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "pKpAmA6XgOfF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('reviews.sqlite')\n",
        "c = conn.cursor()\n",
        "c.execute(\"SELECT * FROM review_db WHERE date\" \" BETWEEN '2017-01-01 00:00:00' AND DATETIME('now')\")\n",
        "results = c.fetchall()\n",
        "conn.close()\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaUqutjYiETh",
        "outputId": "6d51a43b-e9e4-405c-a341-230756dde746"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I love this movie', 1, '2024-05-06 01:32:47'), ('I disliked this movie', 0, '2024-05-06 01:32:47')]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}